# Prepare data (normalize + risk bands)
python scripts/prepare_data.py --config configs/default.yaml

# Train LR baseline + per-language temperature
python scripts/train_calibrate.py --config configs/default.yaml

# Evaluate CP (global + Mondrian by risk band), write JSONs & plots to data/processed/
python scripts/eval_cp.py --config configs/default.yaml

# Generate plots and Section 4 text
python scripts/plot_results.py
python scripts/export_section4.py
ğŸ”¬ Method summary

Normalization ([T3]/[I2]): Arabic diacritics removal, alif/yÄÊ¾ canonicalization, clitic segmentation; English lemmatization; Unicode safety checks.

Risk vector 
ğ‘…(ğ‘¥)
R(x) ([T2]/[I2]): URL presence, digit count (Latin + Arabic-Indic), long message length; Arabic only: zero-width controls, confusables.

Vectorizers ([T4]): TF-IDF word 1â€“2 + char 3â€“5; strong baseline for SMS.

Baseline & temperature ([T5â€“T6]): LR + per-language temperature (Platt) for calibrated probabilities.

Conformal Prediction ([T7]/[I6]): split CP; Mondrian per cell 
ğ‘š=(ğ‘™ğ‘ğ‘›ğ‘”ğ‘¢ğ‘ğ‘”ğ‘’,ğ‘Ÿğ‘–ğ‘ ğ‘˜)m=(language,risk); coverage vs. 
Î±, ASS, Singleton/Abstention, per-band audits.
